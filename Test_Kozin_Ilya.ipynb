{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_Kozin_Ilya.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/A2XoDwW2f5zhqEHDk3ne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KozinIlya/Test/blob/main/Test_Kozin_Ilya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Комментраии к работе:\n",
        "\n",
        "Получившийся скрипт считает долго и есть предположение что эффективнее было бы вытащить revenue методом описанным в [здесь](https://konstantinklepikov.github.io/2020/03/30/preprocessing-of-json-data-to-pandas-on-python.html)\n",
        "\n",
        " Для \"быстрого\" учета статистической значимости обрезал выбросы снизу. Апппаратные методы (метод 3-х сигм, отбрасывание n-го процентиля) хорошего результата не дали, поэтому нижний порог для количества просмотров подобрал исходя из \"экспертной оценки\".\n",
        "Более хорошим был бы вариант сглаживания среднего значения revenue для пользователей с маленьким количеством просмотров по формуле: \n",
        "Сглаженный_mean = сумма_revenue+a*global_mean/count_revenue +а\n",
        "\n",
        "Где: а - коэффициент сглаживания.\n",
        "\n",
        "\n",
        " Из интересных особенностей стоит отметить, хотя основной доход, приносят большие города, их нет в топе по eCPM. \n",
        "\n",
        " Большое количество просматривало рекламу 1 раз.\n",
        "\n",
        " Свежие OS выглядят намного бодрее как по eCPM, так и по сумме доходов. Возможно проблемы в работе приложения на старых OS.\n",
        "\n"
      ],
      "metadata": {
        "id": "hogcFbdruwiI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6IoaAQUwQGv"
      },
      "outputs": [],
      "source": [
        "! gdown --id 1h2eXP4EyL8hYT2kZ0wmShAtp8Qz8HpNq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pandas.io.json import json_normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/us events ad_revenue filtered 03.02-07.02.csv')\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "sFEqYIBwxiPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Удаляем ненужные данные\n",
        "df1 = df.drop(columns=['device_manufacturer', 'device_model','device_type','device_locale',\n",
        "                       'event_name','connection_type','operator_name','country_iso_code',\n",
        "                       'event_timestamp','event_receive_datetime','event_receive_timestamp'])\n",
        "df1 = df1.dropna(subset=['profile_id'])                           #удаляем строки без ID\n",
        "df1['event_datetime'] = pd.to_datetime(df1['event_datetime'])     # меняем формат на datetime\n",
        "df1.info()\n",
        "#df1 = df1.head(10000)        # ограничение строк для отладки скрипта"
      ],
      "metadata": {
        "id": "h5xx72PBHs-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создаем новый датафрейм с столбцом revenue (из столбца event_json)\n",
        "revenue = []\n",
        "id = []\n",
        "os = []\n",
        "datetime = []\n",
        "city = []\n",
        "\n",
        "for i, row in df1.iterrows():\n",
        "  t = df1['event_json'][i]\n",
        "  data_list = json.loads(t)\n",
        "  df_1 = json_normalize(data_list)\n",
        "  p = df_1.revenue.item()\n",
        "  revenue.append(p)\n",
        "  id.append(row['profile_id'])\n",
        "  os.append(row['os_version'])\n",
        "  datetime.append(row['event_datetime'])\n",
        "  city.append(row['city'])\n",
        "\n",
        "  \n",
        "df_with_revenue = pd.DataFrame({'id':id, 'os':os,'revenue':revenue,'datetime':datetime,'city':city})\n",
        "df_with_revenue.head(3)"
      ],
      "metadata": {
        "id": "fe3XndDWNXXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "iterable_list = ['id','city','os']\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20,8))\n",
        "\n",
        "for j, i in enumerate(iterable_list):\n",
        "  agg_func_math = {\n",
        "      'revenue': ['sum','count', 'mean' ]\n",
        "  }\n",
        "\n",
        "  df_with_rev = df_with_revenue.groupby([i]).agg(agg_func_math).reset_index() \n",
        "  df_with_rev.columns = [tup[1] if tup[1] else tup[0] for tup in df_with_rev.columns]  #ставим заголовки на один уровень\n",
        "  \n",
        "  if i == 'id':\n",
        "    p = df_with_rev[df_with_rev['count'] > 100]           #убираем юзеров с количеством просмотров >100\n",
        "    p['eCPM_mean'] = p['mean'] *1000                            #  средний   eCPM на юзера    \n",
        "    axes[j].hist(p['eCPM_mean'], bins=100)\n",
        "    axes[j].set_ylabel('количество юзеров')\n",
        "    axes[j].set_title(f\"распределение среднего eCPM по {i}\")\n",
        "  else:\n",
        "    p = df_with_rev[df_with_rev['count'] > 500]                #убираем города  с количеством просмотров >1000 (осей с такими параметрами нет)                \n",
        "    p['eCPM_mean'] = p['mean'] *1000         #  средний   eCPM на ось/город\n",
        "    if i == 'os':\n",
        "      axes[j].bar(p['os'],p['eCPM_mean'],)\n",
        "      axes[j].set_ylabel('средний eCPM')\n",
        "      axes[j].set_xlabel('версия OS')\n",
        "      axes[j].set_title(i)\n",
        "    elif i == 'city':\n",
        "      axes[j].hist(p['eCPM_mean'], bins=100)\n",
        "      axes[j].set_ylabel('количество городов')\n",
        "      axes[j].set_title(f\"распределение среднего eCPM по {i}\")\n",
        "  \n",
        "  print()\n",
        "  print( )\n",
        "  print(f\"         Топ10 {i} по eCPM_mean\")\n",
        "  print()\n",
        "  display(p.sort_values(by = 'eCPM_mean', ascending=False).head(10))\n"
      ],
      "metadata": {
        "id": "Hzws6xykr5Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#сумарные доходы по городам и OS\n",
        "df_with_revenue\n",
        "spisok = ['city', 'os']\n",
        "for i in spisok:\n",
        "  sum_i = df_with_revenue.groupby(df_with_revenue[i])[['revenue']].sum().round(2).reset_index()\n",
        "  print()\n",
        "  print( )\n",
        "  print(f\"         Топ {i} по суммарным доходам\")\n",
        "  print()\n",
        "  display(sum_i.sort_values(by = 'revenue', ascending=False).head(15))"
      ],
      "metadata": {
        "id": "UWNWwE5PAe-i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}